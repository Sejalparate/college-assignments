{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inbuilt PoS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sejbp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sejbp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text = \"I am going to the park with my friends tomorrow in the evening and we will play football together\"\n",
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('park', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('friends', 'NNS'),\n",
       " ('tomorrow', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('evening', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('play', 'VB'),\n",
       " ('football', 'NN'),\n",
       " ('together', 'RB')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PoS tagging\n",
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "tagged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package indian to\n",
      "[nltk_data]     C:\\Users\\sejbp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('indian')\n",
    "from nltk.tag import tnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text = \"ऑनलाइन शिक्षा में शिक्षक अपने छात्रों से संपर्क साधने के लिए स्काइप, ज़ूम आदि ऐप्प के माध्यम से जुड़ते है\"\n",
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = nltk.corpus.indian.tagged_sents('hindi.pos')\n",
    "tnt_pos_tagger = tnt.TnT()\n",
    "tnt_pos_tagger.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ऑनलाइन', 'Unk'),\n",
       " ('शिक्षा', 'Unk'),\n",
       " ('में', 'PREP'),\n",
       " ('शिक्षक', 'Unk'),\n",
       " ('अपने', 'PRP'),\n",
       " ('छात्रों', 'Unk'),\n",
       " ('से', 'PREP'),\n",
       " ('संपर्क', 'Unk'),\n",
       " ('साधने', 'Unk'),\n",
       " ('के', 'PREP'),\n",
       " ('लिए', 'PREP'),\n",
       " ('स्काइप', 'Unk'),\n",
       " (',', 'PUNC'),\n",
       " ('ज़ूम', 'Unk'),\n",
       " ('आदि', 'RP'),\n",
       " ('ऐप्प', 'Unk'),\n",
       " ('के', 'PREP'),\n",
       " ('माध्यम', 'NN'),\n",
       " ('से', 'PREP'),\n",
       " ('जुड़ते', 'Unk'),\n",
       " ('है', 'VAUX')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_tokens = tnt_pos_tagger.tag(tokens)\n",
    "tagged_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expression based PoS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag(sentence):\n",
    "    tags = []\n",
    "    words = sentence.split()\n",
    "    for word in words:\n",
    "        if re.match(r'^(I|me|you|he|him|she|her|it|we|us|they|them)$', word):  # Pronoun\n",
    "            tags.append('PRP')\n",
    "        elif re.match(r'^[A-Z][a-z]*$', word):  # Proper Noun\n",
    "            tags.append('NNP')\n",
    "        elif re.match(r'^to$', word):  # to\n",
    "            tags.append('TO')\n",
    "        elif re.match(r'^[A-Z][a-z]*$', word):  # Noun\n",
    "            tags.append('NN')\n",
    "        elif re.match(r'^(on|in|at|by|for|with|of|to)$', word):  # Preposition\n",
    "            tags.append('IN')\n",
    "        elif re.match(r'^(and|or|but|while|if|then)$', word):  # Conjunction\n",
    "            tags.append('CC')\n",
    "        elif re.match(r'^(a|an|the)$', word):  # Determiner\n",
    "            tags.append('DT')\n",
    "        elif re.match(r'^[a-z]+(ing)$', word):  # Verb (Gerund)\n",
    "            tags.append('VBG')\n",
    "        elif re.match(r'^[a-z]+$', word):  # Verb (Base Form)\n",
    "            tags.append('VB')\n",
    "        elif re.match(r'^[a-z]+ly$', word):  # Adverb\n",
    "            tags.append('RB')\n",
    "        elif re.match(r'^[a-z]+(ous|ful|ive|ish|able)$', word):  # Adjective\n",
    "            tags.append('JJ')\n",
    "        elif re.match(r'^[.,?!]$', word):  # Punctuation\n",
    "            tags.append('PUNC')\n",
    "        elif re.match(r'^[0-9]+$', word):  # Cardinal Number\n",
    "            tags.append('CD')\n",
    "        elif re.match(r'^[A-Z]+$', word):  # Foreign Word or Abbreviation\n",
    "            tags.append('FW')\n",
    "        else:\n",
    "            tags.append('UNKNOWN')\n",
    "    return list(zip(words, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VB'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('park', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('my', 'VB'),\n",
       " ('friends', 'VB'),\n",
       " ('tomorrow', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('evening', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('will', 'VB'),\n",
       " ('play', 'VB'),\n",
       " ('football', 'VB'),\n",
       " ('together', 'VB')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I am going to the park with my friends tomorrow in the evening and we will play football together\"\n",
    "pos_tag_regex = pos_tag(sentence)\n",
    "pos_tag_regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary-based PoS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = {\n",
    "    \"I\": \"PRP\", \"am\": \"VBP\", \"going\": \"VBG\", \"to\": \"TO\",\n",
    "    \"the\": \"DT\", \"park\": \"NN\", \"with\": \"IN\", \"my\": \"PRP$\",\n",
    "    \"friends\": \"NNS\", \"tomorrow\": \"NN\", \"in\": \"IN\", \"the\": \"DT\",\n",
    "    \"evening\": \"NN\", \"and\": \"CC\", \"we\": \"PRP\", \"will\": \"MD\",\n",
    "    \"play\": \"VB\", \"football\": \"NN\", \"together\": \"RB\"\n",
    "}\n",
    "\n",
    "def pos_tag(sentence):\n",
    "    words = sentence.split()\n",
    "    tagged_sentence = []\n",
    "    for word in words:\n",
    "        if word in pos_dict:\n",
    "            tagged_sentence.append((word, pos_dict[word]))\n",
    "        else:\n",
    "            tagged_sentence.append((word, \"UNKNOWN\"))\n",
    "    return tagged_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('park', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('friends', 'NNS'),\n",
       " ('tomorrow', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('evening', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('play', 'VB'),\n",
       " ('football', 'NN'),\n",
       " ('together.', 'UNKNOWN')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I am going to the park with my friends tomorrow in the evening and we will play football together.\"\n",
    "tagged_sentence = pos_tag(sentence)\n",
    "tagged_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram model based PoS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\sejbp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "C:\\Users\\sejbp\\AppData\\Local\\Temp\\ipykernel_17736\\2392206354.py:18: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(\"Unigram Tagger Accuracy:\", unigram_tagger.evaluate(test_sents))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Tagger Accuracy: 0.8608213982733669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sejbp\\AppData\\Local\\Temp\\ipykernel_17736\\2392206354.py:19: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(\"Bigram Tagger Accuracy:\", bigram_tagger.evaluate(test_sents))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Tagger Accuracy: 0.1132791057437996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sejbp\\AppData\\Local\\Temp\\ipykernel_17736\\2392206354.py:20: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(\"Trigram Tagger Accuracy:\", trigram_tagger.evaluate(test_sents))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Tagger Accuracy: 0.06736863116922003\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "from nltk.tag import UnigramTagger, BigramTagger, TrigramTagger\n",
    "\n",
    "# Load the Treebank corpus\n",
    "nltk.download('treebank')\n",
    "tagged_sentences = treebank.tagged_sents()\n",
    "\n",
    "# Split the tagged sentences into training and testing sets\n",
    "train_size = int(0.8 * len(tagged_sentences))\n",
    "train_sents = tagged_sentences[:train_size]\n",
    "test_sents = tagged_sentences[train_size:]\n",
    "\n",
    "unigram_tagger = UnigramTagger(train_sents)\n",
    "bigram_tagger = BigramTagger(train_sents)\n",
    "trigram_tagger = TrigramTagger(train_sents)\n",
    "\n",
    "# Evaluate taggers on test data\n",
    "print(\"Unigram Tagger Accuracy:\", unigram_tagger.evaluate(test_sents))\n",
    "print(\"Bigram Tagger Accuracy:\", bigram_tagger.evaluate(test_sents))\n",
    "print(\"Trigram Tagger Accuracy:\", trigram_tagger.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tagging the sample sentence using each tagger:\n",
      "Unigram Tagger: [('I', 'PRP'), ('am', None), ('going', 'VBG'), ('to', 'TO'), ('the', 'DT'), ('park', 'NN'), ('with', 'IN'), ('my', 'PRP$'), ('friends', 'NNS'), ('tomorrow', 'NN'), ('in', 'IN'), ('the', 'DT'), ('evening', 'NN'), ('and', 'CC'), ('we', 'PRP'), ('will', 'MD'), ('play', 'VB'), ('football', 'NN'), ('together', 'RB')]\n",
      "Bigram Tagger: [('I', 'PRP'), ('am', None), ('going', None), ('to', None), ('the', None), ('park', None), ('with', None), ('my', None), ('friends', None), ('tomorrow', None), ('in', None), ('the', None), ('evening', None), ('and', None), ('we', None), ('will', None), ('play', None), ('football', None), ('together', None)]\n",
      "Trigram Tagger: [('I', 'PRP'), ('am', None), ('going', None), ('to', None), ('the', None), ('park', None), ('with', None), ('my', None), ('friends', None), ('tomorrow', None), ('in', None), ('the', None), ('evening', None), ('and', None), ('we', None), ('will', None), ('play', None), ('football', None), ('together', None)]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I am going to the park with my friends tomorrow in the evening and we will play football together\"\n",
    "\n",
    "# Tag the sample sentence using each tagger\n",
    "print(\"\\nTagging the sample sentence using each tagger:\")\n",
    "print(\"Unigram Tagger:\", unigram_tagger.tag(nltk.word_tokenize(sentence)))\n",
    "print(\"Bigram Tagger:\", bigram_tagger.tag(nltk.word_tokenize(sentence)))\n",
    "print(\"Trigram Tagger:\", trigram_tagger.tag(nltk.word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
